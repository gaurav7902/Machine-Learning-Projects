{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f17977bf-80dc-4176-a5f7-16360128530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c828a5a1-4c1d-4221-a793-99b28e2243e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassLogisticRegression:\n",
    "    def __init__(self, learning_rate=0.3, num_iterations=1000, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Initialize Multi-class Logistic Regression model\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.threshold = threshold\n",
    "        self.weights = None\n",
    "        self.biases = None\n",
    "        self.n_classes = None\n",
    "        \n",
    "    def softmax(self, z):\n",
    "        \"\"\"\n",
    "        Compute softmax function for multi-class classification\n",
    "        \"\"\"\n",
    "        shifted_z = z - np.max(z, axis=1, keepdims=True)\n",
    "        exp_z = np.exp(shifted_z)\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "    \n",
    "    def initialize_parameters(self, num_features, num_classes):\n",
    "        \"\"\"\n",
    "        Initialize weights and biases for each class\n",
    "        \"\"\"\n",
    "        self.n_classes = num_classes\n",
    "        self.weights = np.zeros((num_features, num_classes))\n",
    "        self.biases = np.zeros(num_classes)\n",
    "        \n",
    "    def compute_cost(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Compute cross-entropy loss for multi-class classification\n",
    "        \"\"\"\n",
    "        m = len(y_true)\n",
    "        epsilon = 1e-15\n",
    "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "        return -np.sum(y_true * np.log(y_pred)) / m\n",
    "    \n",
    "    def one_hot_encode(self, y):\n",
    "        \"\"\"\n",
    "        Convert class labels to one-hot encoded format\n",
    "        \"\"\"\n",
    "        m = len(y)\n",
    "        y_one_hot = np.zeros((m, self.n_classes))\n",
    "        for i in range(m):\n",
    "            y_one_hot[i, y[i]] = 1\n",
    "        return y_one_hot\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the model using gradient descent\n",
    "        \"\"\"\n",
    "        m, n = X.shape\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        self.initialize_parameters(n, self.n_classes)\n",
    "        \n",
    "        # Convert y to one-hot encoded format\n",
    "        y_one_hot = self.one_hot_encode(y)\n",
    "        \n",
    "        # Early stopping parameters\n",
    "        epsilon = 1e-5\n",
    "        patience = 5\n",
    "        best_cost = np.inf\n",
    "        no_improvement_count = 0\n",
    "        costs = []\n",
    "        \n",
    "        for iteration in range(self.num_iterations):\n",
    "            # Forward propagation\n",
    "            z = np.dot(X, self.weights) + self.biases\n",
    "            y_pred = self.softmax(z)\n",
    "            \n",
    "            # Compute cost\n",
    "            cost = self.compute_cost(y_one_hot, y_pred)\n",
    "            costs.append(cost)\n",
    "            \n",
    "            # Early stopping check\n",
    "            if cost < best_cost - epsilon:\n",
    "                best_cost = cost\n",
    "                no_improvement_count = 0\n",
    "            else:\n",
    "                no_improvement_count += 1\n",
    "            \n",
    "            if no_improvement_count >= patience:\n",
    "                print(f\"Early stopping at iteration {iteration}\")\n",
    "                break\n",
    "            \n",
    "            # Compute gradients\n",
    "            dz = y_pred - y_one_hot\n",
    "            dw = (1/m) * np.dot(X.T, dz)\n",
    "            db = (1/m) * np.sum(dz, axis=0)\n",
    "            \n",
    "            # Update parameters\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.biases -= self.learning_rate * db\n",
    "            \n",
    "            if iteration % 100 == 0:\n",
    "                print(f\"Iteration {iteration}: Cost = {cost:.4f}\")\n",
    "        \n",
    "        return costs\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Predict class probabilities\n",
    "        \"\"\"\n",
    "        z = np.dot(X, self.weights) + self.biases\n",
    "        return self.softmax(z)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict class labels\n",
    "        \"\"\"\n",
    "        probas = self.predict_proba(X)\n",
    "        return np.argmax(probas, axis=1)\n",
    "    \n",
    "    def accuracy_score(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate accuracy score from scratch\n",
    "        \"\"\"\n",
    "        return np.sum(y_true == y_pred) / len(y_true)\n",
    "    \n",
    "    def confusion_matrix(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Compute confusion matrix from scratch\n",
    "        \"\"\"\n",
    "        matrix = np.zeros((self.n_classes, self.n_classes), dtype=int)\n",
    "        for t, p in zip(y_true, y_pred):\n",
    "            matrix[t, p] += 1\n",
    "        return matrix\n",
    "    \n",
    "    def class_metrics(self, confusion_matrix):\n",
    "        \"\"\"\n",
    "        Compute precision, recall, and f1-score for each class\n",
    "        \"\"\"\n",
    "        metrics = {}\n",
    "        for class_idx in range(self.n_classes):\n",
    "            # True Positives: diagonal elements\n",
    "            tp = confusion_matrix[class_idx, class_idx]\n",
    "            \n",
    "            # False Positives: sum of column minus TP\n",
    "            fp = np.sum(confusion_matrix[:, class_idx]) - tp\n",
    "            \n",
    "            # False Negatives: sum of row minus TP\n",
    "            fn = np.sum(confusion_matrix[class_idx, :]) - tp\n",
    "            \n",
    "            # Calculate metrics\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            \n",
    "            metrics[f\"Class {class_idx}\"] = {\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"f1-score\": f1,\n",
    "                \"support\": np.sum(confusion_matrix[class_idx, :])\n",
    "            }\n",
    "        \n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fce2c54d-d4d0-45c5-b436-6ba99a4cc8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Cost = 1.6094\n",
      "Early stopping at iteration 5\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load and prepare data\n",
    "    df = pd.read_csv(\"multi_classification_train.csv\")\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.iloc[:, 1:-1].values  # All features except ID and Class\n",
    "    y = df.iloc[:, -1].values    # Class column\n",
    "    \n",
    "    # Create and train model\n",
    "    model = MultiClassLogisticRegression(learning_rate=0.1, num_iterations=1000)\n",
    "    costs = model.fit(X, y)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Calculate metrics from scratch\n",
    "    accuracy = model.accuracy_score(y, y_pred)\n",
    "    conf_matrix = model.confusion_matrix(y, y_pred)\n",
    "    class_metrics = model.class_metrics(conf_matrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e8bf164-090f-45b0-8232-5aaf88dc16e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy: 0.5476\n"
     ]
    }
   ],
   "source": [
    " print(f\"\\nTraining Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ac38735-c430-4f82-98d9-05affe05f129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[  101     8   704  2696   531]\n",
      " [    1   563  4284  3129  3427]\n",
      " [    0     9 15523   992    94]\n",
      " [    0     4  2027  7988    45]\n",
      " [    1     9  1713  2040  2111]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7ce5afd-71e2-44b2-b1ba-4d9c6f212b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Metrics by Class:\n",
      "\n",
      "Class 0:\n",
      "precision: 0.9806\n",
      "recall: 0.0250\n",
      "f1-score: 0.0488\n",
      "support: 4040.0000\n",
      "\n",
      "Class 1:\n",
      "precision: 0.9494\n",
      "recall: 0.0494\n",
      "f1-score: 0.0939\n",
      "support: 11404.0000\n",
      "\n",
      "Class 2:\n",
      "precision: 0.6401\n",
      "recall: 0.9341\n",
      "f1-score: 0.7596\n",
      "support: 16618.0000\n",
      "\n",
      "Class 3:\n",
      "precision: 0.4742\n",
      "recall: 0.7937\n",
      "f1-score: 0.5937\n",
      "support: 10064.0000\n",
      "\n",
      "Class 4:\n",
      "precision: 0.3400\n",
      "recall: 0.3594\n",
      "f1-score: 0.3494\n",
      "support: 5874.0000\n"
     ]
    }
   ],
   "source": [
    "    print(\"\\nDetailed Metrics by Class:\")\n",
    "    for class_name, metrics in class_metrics.items():\n",
    "        print(f\"\\n{class_name}:\")\n",
    "        for metric_name, value in metrics.items():\n",
    "            print(f\"{metric_name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b271b793-5be3-4eac-aa4d-b4891ef69d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'predictions.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare the test data\n",
    "test_df = pd.read_csv(\"multi_classification_test.csv\")\n",
    "\n",
    "# Separate features and true labels\n",
    "X_test = test_df.iloc[:, 1:].values  # All features except ID and Class\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "output_df = pd.DataFrame({\n",
    "    \"ID\": test_df.iloc[:, 0],  # Assuming the first column is an identifier\n",
    "    \"Predicted_Class\": y_test_pred\n",
    "})\n",
    "\n",
    "# Optionally, add probabilities for each class\n",
    "for i in range(model.n_classes):\n",
    "    output_df[f\"Probability_Class_{i}\"] = y_test_pred_proba[:, i]\n",
    "\n",
    "# Save to file\n",
    "output_df.to_csv(\"predictions.csv\", index=False)\n",
    "\n",
    "print(\"Predictions saved to 'predictions.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593d3b45-c1f7-4efc-8625-898815035be4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
